import streamlit as st
import google.generativeai as genai
import pandas as pd
from PIL import Image
import io
import fitz  # PyMuPDF

# --- Page Configuration ---
st.set_page_config(page_title="Ø§Ù„Ù…ØµØ­Ø­ Ø§Ù„Ø°ÙƒÙŠ V13", layout="wide")

# --- UI Styling ---
st.markdown("""
<style>
    .stApp { direction: rtl; }
    h1, h2, h3, p, div, label, .stMarkdown, .stExpander, .stCheckbox { text-align: right; }
    .stDataFrame { direction: rtl; }
    .stRadio > label { font-weight: bold; font-size: 1.2rem; }
</style>
""", unsafe_allow_html=True)

# --- Sidebar Configuration ---
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    
    # User-provided API Key
    user_api_key = st.text_input("ğŸ”‘ Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ Gemini API Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ:", type="password", help="Ø§Ù„Ù…ÙØªØ§Ø­ Ø®Ø§Øµ Ø¨Ùƒ ÙˆÙ„Ø§ ÙŠØªÙ… Ø­ÙØ¸Ù‡ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø§Ø¯Ù….")
    
    st.divider()
    # Restricted model selection
    model_name = st.selectbox("ğŸ§  Ø§Ù„Ù…Ø­Ø±Ùƒ:", ["gemini-2.5-pro", "gemini-2.5-flash"], index=0)
    
    if not user_api_key:
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ API Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©.")

# --- Processing Functions ---
def smart_split(image, page_num):
    width, height = image.size
    if width > height * 1.1:
        right_half = image.crop((width // 2, 0, width, height)) 
        left_half = image.crop((0, 0, width // 2, height))     
        return [right_half, left_half], f"ØµÙØ­Ø© {page_num}: Ø¹Ø±ÙŠØ¶Ø© (ØªÙ… Ù‚ØµÙ‡Ø§ âœ‚ï¸)"
    else:
        return [image], f"ØµÙØ­Ø© {page_num}: Ø¹Ø§Ø¯ÙŠØ© (âœ…)"

def process_file_smartly(file):
    if file is None: return [], []
    raw_images = []
    logs = []
    final_processed_images = []
    
    if file.type in ['image/png', 'image/jpeg', 'image/jpg']:
        raw_images.append(Image.open(file))
    elif file.name.endswith('.pdf'):
        doc = fitz.open(stream=file.read(), filetype="pdf")
        for i in range(len(doc)):
            page = doc.load_page(i)
            pix = page.get_pixmap(dpi=200) 
            raw_images.append(Image.open(io.BytesIO(pix.tobytes())))
    
    for idx, img in enumerate(raw_images):
        split_imgs, log = smart_split(img, idx + 1)
        final_processed_images.extend(split_imgs)
        logs.append(log)
        
    return final_processed_images, logs

# --- Main Interface ---
st.title("ğŸ›¡ï¸ Ø§Ù„Ù…ØµØ­Ø­ Ø§Ù„Ø°ÙƒÙŠ (V13 - Gemini 2.5)")

# --- Section 1: Answer Key Setup ---
st.subheader("1ï¸âƒ£ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØ©")

grading_mode = st.radio(
    "Ù…ØµØ¯Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:",
    ("Ø£- Ù„Ø¯ÙŠ Ù…Ù„Ù Ø¥Ø¬Ø§Ø¨Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ø¬Ø§Ù‡Ø²", 
     "Ø¨- Ù„ÙŠØ³ Ù„Ø¯ÙŠ Ù†Ù…ÙˆØ°Ø¬ (ØªÙˆÙ„ÙŠØ¯ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ)")
)

final_model_content = []  
q_file_uploaded = None 

if grading_mode == "Ø£- Ù„Ø¯ÙŠ Ù…Ù„Ù Ø¥Ø¬Ø§Ø¨Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ø¬Ø§Ù‡Ø²":
    t_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", type=['pdf', 'png', 'jpg'])
    if t_file:
        model_images, _ = process_file_smartly(t_file)
        if model_images:
            final_model_content = ["\n--- [ØµÙˆØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¹ØªÙ…Ø¯] ---", *model_images]
            st.success(f"âœ… ØªÙ… Ø§Ø¹ØªÙ…Ø§Ø¯ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")

else: 
    q_file_uploaded = st.file_uploader("Ø§Ø±ÙØ¹ ÙˆØ±Ù‚Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙÙ‚Ø·", type=['pdf', 'png', 'jpg'])
    if 'ai_generated_key' not in st.session_state:
        st.session_state.ai_generated_key = None

    if q_file_uploaded and user_api_key:
        if st.button("ğŸ‘ï¸ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙˆÙ„Ø¯"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø­Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ..."):
                try:
                    genai.configure(api_key=user_api_key)
                    model = genai.GenerativeModel(model_name)
                    q_imgs, _ = process_file_smartly(q_file_uploaded)
                    res = model.generate_content(["Ø­Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø§Ù…ØªØ­Ø§Ù† Ø¨Ø¯Ù‚Ø© Ù„ÙŠÙƒÙˆÙ† Ù†Ù…ÙˆØ°Ø¬Ø§Ù‹ Ù„Ù„ØªØµØ­ÙŠØ­.", *q_imgs])
                    st.session_state.ai_generated_key = res.text
                except Exception as e:
                    st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
    
    if st.session_state.ai_generated_key:
        with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙˆÙ„Ø¯"): st.markdown(st.session_state.ai_generated_key)
        final_model_content = ["\n--- [Ù†Ù…ÙˆØ°Ø¬ Ù…ÙˆÙ„Ø¯] ---", st.session_state.ai_generated_key]

# --- Section 2: Student Submissions ---
st.divider()
st.subheader("2ï¸âƒ£ Ù…Ù„ÙØ§Øª Ø§Ù„Ø·Ù„Ø§Ø¨")
student_files = st.file_uploader("Ø±ÙØ¹ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø·Ù„Ø§Ø¨", type=['pdf', 'png', 'jpg'], accept_multiple_files=True)

# --- Section 3: Grading Execution ---
if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØµØ­ÙŠØ­"):
    if not user_api_key:
        st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ API Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©.")
        st.stop()
    
    if not final_model_content and q_file_uploaded:
        # Auto-generate key if not already done
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø£ÙˆÙ„Ø§Ù‹..."):
            try:
                genai.configure(api_key=user_api_key)
                model = genai.GenerativeModel(model_name)
                q_file_uploaded.seek(0)
                q_imgs, _ = process_file_smartly(q_file_uploaded)
                res = model.generate_content(["Ø­Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø§Ù…ØªØ­Ø§Ù† Ø¨Ø¯Ù‚Ø©.", *q_imgs])
                final_model_content = ["\n--- [Ù†Ù…ÙˆØ°Ø¬ Ù…ÙˆÙ„Ø¯] ---", res.text]
            except Exception as e:
                st.error(f"ÙØ´Ù„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯: {e}")
                st.stop()

    if not final_model_content:
        st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªÙˆÙÙŠØ± Ù…Ù„Ù Ø¥Ø¬Ø§Ø¨Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ø£Ùˆ ÙˆØ±Ù‚Ø© Ø£Ø³Ø¦Ù„Ø©.")
    elif not student_files:
        st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ø·Ù„Ø§Ø¨.")
    else:
        genai.configure(api_key=user_api_key)
        model = genai.GenerativeModel(model_name)
        results = []
        progress_bar = st.progress(0)
        
        for i, s_file in enumerate(student_files):
            s_images, _ = process_file_smartly(s_file)
            try:
                prompt = [
                    "Ø£Ù†Øª Ù…ØµØ­Ø­ Ø§Ù…ØªØ­Ø§Ù†Ø§Øª Ø®Ø¨ÙŠØ±. Ù‚Ø§Ø±Ù† Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ø§Ù„ØªÙ†Ø³ÙŠÙ‚: Ø§Ù„Ø§Ø³Ù… | Ø§Ù„Ø¹Ù„Ø§Ù…Ø© | Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©",
                    *final_model_content,
                    "\n--- [Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø·Ø§Ù„Ø¨] ---",
                    *s_images
                ]
                response = model.generate_content(prompt)
                raw_text = response.text
                
                # Simple parsing logic
                try:
                    parts = raw_text.split('\n')[0].split('|')
                    name = parts[0].strip()
                    grade = parts[1].strip()
                except:
                    name, grade = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ", "ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©"
                
                results.append({"Ø§Ù„Ù…Ù„Ù": s_file.name, "Ø§Ù„Ø·Ø§Ù„Ø¨": name, "Ø§Ù„Ø¯Ø±Ø¬Ø©": grade, "Ø§Ù„ØªÙØ§ØµÙŠÙ„": raw_text})
            except Exception as e:
                results.append({"Ø§Ù„Ù…Ù„Ù": s_file.name, "Ø§Ù„Ø·Ø§Ù„Ø¨": "Ø®Ø·Ø£", "Ø§Ù„Ø¯Ø±Ø¬Ø©": "0", "Ø§Ù„ØªÙØ§ØµÙŠÙ„": str(e)})
            
            progress_bar.progress((i + 1) / len(student_files))
        
        st.success("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØµØ­ÙŠØ­!")
        df = pd.DataFrame(results)
        st.dataframe(df)
        
        # Download results
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False)
        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Excel)", output.getvalue(), "Grades_V13.xlsx")
